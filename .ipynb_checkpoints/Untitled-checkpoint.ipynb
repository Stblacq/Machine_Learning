{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95240829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import plot, show, xlabel, ylabel, suptitle\n",
    "from pandas import DataFrame, read_csv, to_datetime, concat\n",
    "from sklearn.metrics import r2_score, mean_poisson_deviance, mean_squared_error, mean_absolute_error\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "class FlightDelayPredictor:\n",
    "    \"\"\"\n",
    "     A b regression prediction class\n",
    "     contains the blue print of a prediction class\n",
    "     \"\"\"\n",
    "    date_time_fields = ['Scheduled depature time', 'Scheduled arrival time']\n",
    "    categorical_variables = ['Depature Airport', 'Destination Airport']\n",
    "\n",
    "    def __init__(self, path_to_dataset_csv):\n",
    "        \"\"\"\n",
    "        Initialises dataset from dataset from data frame\n",
    "        Uses the last column as Y and the others as X\n",
    "        and calls the split function from subclass if defined\n",
    "        :param path_to_dataset_csv:\n",
    "        \"\"\"\n",
    "        self.dataset: DataFrame = read_csv(path_to_dataset_csv)\n",
    "        self.X = self.dataset.iloc[:, :-1]\n",
    "        self.Y = self.dataset.iloc[:, -1]\n",
    "        self.pre_process_data()\n",
    "        self.X_train, self.X_test, self.Y_train, self.Y_test = self.split_dataset()\n",
    "\n",
    "    def pre_process_data(self):\n",
    "        \"\"\"\n",
    "        performs pre-processing on the data set namely\n",
    "        1.Extract more features from timestamp,->year, month, day, day_of_week\n",
    "        2. Label encode categorical features\n",
    "        3. Add feature flight duration\n",
    "        4. handle missing data\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.declare_datetime_fields()\n",
    "        self.add_flight_duration_column()\n",
    "        self.expand_datetime_fields()\n",
    "        self.label_encode_categorical_variables()\n",
    "        self.handle_missing_values()\n",
    "\n",
    "    def remove_outliers(self):\n",
    "        lof = LocalOutlierFactor(n_neighbors=10)\n",
    "        outlier_prediction = lof.fit_predict(self.X_train)\n",
    "        X_Y_train = concat([self.X_train, self.Y_train], axis=1)\n",
    "        X_Y_train['outlier_prediction'] = outlier_prediction\n",
    "        inliers = X_Y_train.query('outlier_prediction == 1').copy(deep=False)\n",
    "        inliers.drop('outlier_prediction', inplace=True, axis=1)\n",
    "        self.X_train, self.Y_train = inliers.iloc[:, :-1], inliers.iloc[:, -1]\n",
    "\n",
    "    def handle_missing_values(self, ):\n",
    "        self.X = self.X.interpolate(method='ffill', limit_direction='forward')\n",
    "\n",
    "    def label_encode_categorical_variables(self):\n",
    "        label_encoder = LabelEncoder()\n",
    "        for field in self.categorical_variables:\n",
    "            self.X[field] = label_encoder.fit_transform(self.X[field])\n",
    "\n",
    "    def add_flight_duration_column(self):\n",
    "        \"\"\"\n",
    "        Add Flight Duration Field\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.X['flight_duration_hours'] = (self.X['Scheduled arrival time'] - self.X[\n",
    "            'Scheduled depature time']) / np.timedelta64(1, 'h')\n",
    "\n",
    "    def expand_datetime_fields(self):\n",
    "        \"\"\"\n",
    "        expands  date_time field into, year, month, day, day_of_week\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for field in self.date_time_fields:\n",
    "            prefix = field.split(\" \")[1]\n",
    "            self.X[f'{prefix}_year'] = self.X[field].dt.year\n",
    "            self.X[f'{prefix}_month'] = self.X[field].dt.month\n",
    "            self.X[f'{prefix}_day'] = self.X[field].dt.day\n",
    "            self.X[f'{prefix}_day_of_week'] = self.X[field].dt.weekday\n",
    "\n",
    "    def drop_date_time_fields(self, dataset):\n",
    "        for field in self.date_time_fields:\n",
    "            dataset.drop(field, inplace=True, axis=1)\n",
    "\n",
    "    def declare_datetime_fields(self):\n",
    "        \"\"\"\n",
    "        change datetime fields from string to datetime types\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for field in self.date_time_fields:\n",
    "            self.X[field] = to_datetime(self.X[field])\n",
    "\n",
    "    def split_dataset(self) -> tuple:\n",
    "        \"\"\"\n",
    "         overrides the base split_dataset method and Split to train_test based on\n",
    "         Scheduled departure time, train with year 2015-2017, test with 2018\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.dataset = concat([self.X, self.Y], axis=1)\n",
    "        dataset_train = self.dataset.query('depature_year < 2018').copy(deep=False)\n",
    "        dataset_test = self.dataset.query('depature_year >= 2018').copy(deep=False)\n",
    "        self.drop_date_time_fields(dataset_train)\n",
    "        self.drop_date_time_fields(dataset_test)\n",
    "        X_train = dataset_train.iloc[:, :-1]\n",
    "        Y_train = dataset_train.iloc[:, -1]\n",
    "\n",
    "        X_test = dataset_test.iloc[:, :-1]\n",
    "        Y_test = dataset_test.iloc[:, -1]\n",
    "\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "    def visualize(self):\n",
    "        \"\"\"\n",
    "        Plots the flight duration x against y\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        xlabel('Flight Duration(hours)', fontsize=18)\n",
    "        ylabel('Delay (minutes)', fontsize=16)\n",
    "        suptitle('Flight Delay Visualization')\n",
    "        plot(self.X_train['flight_duration_hours'], self.Y_train, marker='.')\n",
    "        show()\n",
    "\n",
    "    def train_model(self, model_class, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Takes a sci-kit learn model class and arguments and fits it on the train set\n",
    "        :param model_class:\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        :return: Trained model\n",
    "        \"\"\"\n",
    "        model = model_class(*args, **kwargs)\n",
    "        model.fit(self.X_train, self.Y_train)\n",
    "        return model\n",
    "\n",
    "    def get_best_parameters(self, model_class, param_grid):\n",
    "        \"\"\"\n",
    "        Performs Cross Validation and returns a grid search result of best parameter\n",
    "        :param model_class:\n",
    "        :param param_grid:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        CV_rfc = GridSearchCV(estimator=model_class(), param_grid=param_grid, cv=10)\n",
    "        CV_rfc.fit(self.X_train, self.Y_train)\n",
    "        return CV_rfc.best_params_\n",
    "\n",
    "    def evaluate_model(self, trained_model, X_test=None, Y_test=None):\n",
    "        \"\"\"\n",
    "        Evaluates A trained model and measures its accuracy\n",
    "        :param trained_model:\n",
    "        :param X_test:\n",
    "        :param Y_test:\n",
    "        :return: Accuracy Measures\n",
    "        \"\"\"\n",
    "        X_test = self.X_test if X_test is None else X_test\n",
    "        Y_test = self.Y_test if Y_test is None else Y_test\n",
    "\n",
    "        predictions = trained_model.predict(X_test)\n",
    "        return {\n",
    "            'mean_absolute_error': mean_absolute_error(Y_test, predictions),\n",
    "            'mean_squared_error': mean_squared_error(Y_test, predictions),\n",
    "            'root_mean_squared_error': math.sqrt(mean_squared_error(Y_test, predictions)),\n",
    "            'r2_score': r2_score(Y_test, predictions),\n",
    "#             'mean_poisson_deviance': mean_poisson_deviance(Y_test, predictions)\n",
    "        }\n",
    "\n",
    "\n",
    "# TODO Preprocess Data\n",
    "#          => Extract more features from timestamp,->year, month, day, day_of_week using pandas.Series.dt.\n",
    "#          => One hot encode categorical variables, or use Label Encoder\n",
    "#          => Handle missing Data\n",
    "#          => Split to train_test based on Scheduled departure time, train with year 2015-2017, test with 2018\n",
    "#          => Perform PCA and plot against Y, or plot flight_duration against Y\n",
    "#      Perform Prediction with two or more Models\n",
    "#      Perform Prediction with at least one model with regularisation\n",
    "#      Use Appropriate Evaluation Metric to compare the different models\n",
    "#       Lasso Regression\n",
    "#       Add Ridge Regression\n",
    "#       Check Difference\n",
    "#       Train all models\n",
    "#       Evaluate with train set => Train Error\n",
    "#       Evaluate with test  set => Test Error\n",
    "#       Use GridCV to get hyperparameters\n",
    "#       Outlier Detection and removal\n",
    "\n",
    "\n",
    "# Report\n",
    "predictor = FlightDelayPredictor('./flight_delay.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b624d",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f36a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.remove_outliers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82e1224",
   "metadata": {},
   "source": [
    "### Import Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22002cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor,GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76c75e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_param_grid = [\n",
    "    (LinearRegression, {}),\n",
    "    (Lasso, {\"alpha\": [x * 0.1 for x in range(10, 50,10)]}),\n",
    "\n",
    "    (Ridge, {\"alpha\": [x * 0.1 for x in range(10, 50,10)]}),\n",
    "\n",
    "    (ElasticNet, {\"alpha\": [x * 0.1 for x in range(10, 100,10)], 'l1_ratio': [x * 0.1 for x in range(1, 10)], }),\n",
    "\n",
    "    (AdaBoostRegressor, {'n_estimators': [50, 100, 500, 1000], \"loss\": ['linear', 'square', 'exponential'], }),\n",
    "\n",
    "    (GradientBoostingRegressor,{'n_estimators': [50, 100, 200,]}),\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4a96cd",
   "metadata": {},
   "source": [
    "### Cross Validate And Get Best Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "898d0e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{}, {}, {}, {}, {}, {}, {}, {}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = []\n",
    "for  model_class, parameter_grid in models_param_grid:\n",
    "#     print(f\"Analysing {model_class}\")\n",
    "    best_params.append({})\n",
    "#     best_params.append(predictor.get_best_parameters(model_class, parameter_grid ))\n",
    "#     print(f\"Analysed {model_class}\")\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee902c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model for model,parameter_grid in models_param_grid]\n",
    "models_best_params = list(zip(models,best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a5ffd1",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8841c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training <class 'sklearn.linear_model._base.LinearRegression'>\n",
      "Trained <class 'sklearn.linear_model._base.LinearRegression'>\n",
      "Training <class 'sklearn.linear_model._coordinate_descent.Lasso'>\n",
      "Trained <class 'sklearn.linear_model._coordinate_descent.Lasso'>\n",
      "Training <class 'sklearn.linear_model._ridge.Ridge'>\n",
      "Trained <class 'sklearn.linear_model._ridge.Ridge'>\n",
      "Training <class 'sklearn.linear_model._coordinate_descent.ElasticNet'>\n",
      "Trained <class 'sklearn.linear_model._coordinate_descent.ElasticNet'>\n",
      "Training <class 'sklearn.ensemble._weight_boosting.AdaBoostRegressor'>\n",
      "Trained <class 'sklearn.ensemble._weight_boosting.AdaBoostRegressor'>\n",
      "Training <class 'sklearn.ensemble._gb.GradientBoostingRegressor'>\n",
      "Trained <class 'sklearn.ensemble._gb.GradientBoostingRegressor'>\n",
      "Training <class 'sklearn.svm._classes.SVR'>\n"
     ]
    }
   ],
   "source": [
    "trained_models = []\n",
    "for model,best_params in models_best_params:\n",
    "    print(f\"Training {model}\")\n",
    "    trained_models.append(predictor.train_model(model,**best_params))\n",
    "    print(f\"Trained {model}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284d6452",
   "metadata": {},
   "source": [
    "## Evaluate with Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b511910",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_evaluation = []\n",
    "for model in trained_models:\n",
    "    scores = predictor.evaluate_model(model,predictor.X_train,predictor.Y_train)\n",
    "    training_evaluation.append({\"model\":model,**scores})\n",
    "DataFrame(training_evaluation)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bea0af",
   "metadata": {},
   "source": [
    "## Evaluate with Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3c4d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = []\n",
    "for model in trained_models:\n",
    "    scores = predictor.evaluate_model(model)\n",
    "    evaluation.append({\"model\":model,**scores})\n",
    "\n",
    "DataFrame(evaluation)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea749794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
